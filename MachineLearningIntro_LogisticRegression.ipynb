{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sb\n",
    "import time\n",
    "\n",
    "#\n",
    "# To run this code:\n",
    "# Make sure you have the ml virtualenvironment built and you are working on it.\n",
    "# Start the jupyter notebook within the virtualenv:\n",
    "# > workon ml; ipython notebook\n",
    "#\n",
    "\n",
    "# Dark style to be visualized easier\n",
    "sb.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook walks through an example of building a logistic regression classifier. We walk through the specification of the model, how we get the loss function, and provide two methods for optimizing (one we build ourselves, and another using a standard package).\n",
    "\n",
    "### Background\n",
    "Logistic regression is defined as follows:\n",
    "\n",
    "$$p(x) = \\frac{1}{1 + exp(\\sum_j \\beta_j x_j)}$$\n",
    "\n",
    "$x$ is the input feature vector we'd like to classify.\n",
    "\n",
    "$\\beta$ is a vector of weights, these are the model parameters we will learn from our training data.\n",
    "\n",
    "$p(x)$ is the resulting probability of $x$ belonging to the positive class.\n",
    "\n",
    "**Note**: While it is possible to extend logistic regression to perform multi-class classification, this tutorial focused only on the 2 class problem for clarity.\n",
    "\n",
    "For a more in-depth reference to logistic regression check out this [reference](http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# plot the logistic function\n",
    "#\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "# TODO: tweak the parameters and see how the function changes, \n",
    "# Can you decrease/increase the slope?\n",
    "# Can you change the normalization from [0,1] to [2, 10]?\n",
    "# Can you shift the point at which y = 0.5 from x = 0 to x = 5?\n",
    "y = 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(17,7))\n",
    "ax.set_title('Logistic function', fontsize=16)\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Helper methods\n",
    "#\n",
    "\n",
    "EPS = 1e-16\n",
    "\n",
    "def logistic(betas, feature_vectors):\n",
    "    x = np.array([np.sum(betas * fv) for fv in feature_vectors])\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "def classify(betas, feature_vectors):\n",
    "    out = logistic(betas, feature_vectors)\n",
    "    out_class = out >= 0.5\n",
    "    return out_class\n",
    "\n",
    "\n",
    "def gen_class(n, mu, sig):\n",
    "    return np.random.multivariate_normal(mu, np.eye(len(mu)) * sig, n)\n",
    "\n",
    "\n",
    "# takes an input feature vector and adds a 1 to the end of it\n",
    "def add_bias(data):\n",
    "    data1 = np.array(data[:])\n",
    "    N = len(data1)\n",
    "\n",
    "    if len(data1.shape) == 1:\n",
    "        data1 = data1.reshape(1, N)\n",
    "        data1 = np.append(data1, np.ones((1, 1)), axis=1)\n",
    "    else:\n",
    "        data1 = np.append(data1, np.ones((N, 1)), axis=1)\n",
    "    return data1\n",
    "\n",
    "\n",
    "def accuracy(data, data_class, betas):\n",
    "    pred_class = classify(betas, data)\n",
    "    return np.sum(pred_class == data_class) / (1.0 * len(data_class))\n",
    "\n",
    "\n",
    "def test_result(beta_learned, n):\n",
    "    print('\\ntest data points from class x1')\n",
    "    for i in range(n):\n",
    "        x_test1 = add_bias(gen_class(1, MU1, SIG1))\n",
    "        print(classify(beta_learned, x_test1)[0], logistic(beta_learned, x_test1)[0])\n",
    "\n",
    "    print('\\ntest data points from class x2')\n",
    "    for i in range(n):\n",
    "        x_test2 = add_bias(gen_class(1, MU2, SIG2))\n",
    "        print(classify(beta_learned, x_test2)[0], logistic(beta_learned, x_test2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Generate some data\n",
    "#\n",
    "\n",
    "# number of points in each class\n",
    "N = 100\n",
    "\n",
    "# define parameters for test data\n",
    "# we're generating from a 2d gaussian distribution, so this is the mean vector and the variance\n",
    "MU1 = [3, 0]\n",
    "SIG1 = 1\n",
    "\n",
    "MU2 = [0, 3]\n",
    "SIG2 = 1\n",
    "# TODO: play around with these parameters to see how the classification changes. \n",
    "# what happens when the classes are not linearly separable?\n",
    "\n",
    "# generate 2-d gaussian data with these parameters\n",
    "X1 = gen_class(N, MU1, SIG1)\n",
    "X2 = gen_class(N, MU2, SIG2)\n",
    "data = np.concatenate((X1, X2))\n",
    "\n",
    "# define the classes\n",
    "Y1 = np.ones((N, 1)) * 0\n",
    "Y2 = np.ones((N, 1)) * 1\n",
    "data_class = np.concatenate((Y1, Y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Do a bunch of stuff here to plot the data\n",
    "#\n",
    "import matplotlib.cm as cm\n",
    "colors = cm.rainbow(np.linspace(0, 1, 2))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(15,10))\n",
    "ax.set_title('Dataset', fontsize=16)\n",
    "# plot class 1, then class 2\n",
    "plt.scatter(X1[:, 0], X1[:, 1], s=50, c=colors[0], label='class 1')\n",
    "plt.scatter(X2[:, 0], X2[:, 1], s=50, c=colors[1], label='class 2')\n",
    "legend = ax.legend(loc='upper left', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning \n",
    "\n",
    "We need to build our learning procedure. That is, given our logistic regression model, how can we identify the most appropriate set of weight parameters such that we are able to correctly classify our dataset. To do this, we'll need a bit of math.\n",
    "\n",
    "Remember, the logistic regressor is defined as:\n",
    "$$p(x_i) = \\frac{1}{1 + exp(\\sum_j \\beta_j x_{i,j})}$$\n",
    "\n",
    "This is just plugging a record, $x_i$ into the logistic regression model, where we use $\\beta$ to weight each feature in $x_i$ in order to get our class prediction (i.e. probability of being a \"positive\" example).\n",
    "\n",
    "To learn the appropriate parameters, we will need to define an objective function (sometimes called a loss function) over which we wish to optimize. The objective defines how we go about scoring a model, so we can quantify how good or bad each set of learned parameters is. Once we have this function, we will discuss how to go about optimizing with respect to $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to classify data into one of two classes, so we want to identify an objective function that correctly scores models that classify correctly better than models that make mistakes. There are a couple of ways to go about specifying an objective function and learning the weight parameters, but we will walk through one approach using the [binomial likelihood function](https://en.wikipedia.org/wiki/Binomial_distribution).\n",
    "\n",
    "#### Likelihood function\n",
    "We will define our likelihood function as follows:\n",
    "\n",
    "$$like \\prod_{i} p_i^{y_i} +  (1 - p_i)^{(1 - y_i)}$$\n",
    "\n",
    "To learn the appropriate parameters for our model, we can take the derivative of our likelihood function with respect to each $\\beta_j$. To simplify the derivative, we first take the logarithm of this function (since maximizing the log-likelihood will also maximize the likelihood and it makes the math much simpler).\n",
    "\n",
    "$$llike = \\sum_{i} y_i log(p_i) + (1 - y_i) log(1 - p_i)$$\n",
    "\n",
    "Next, we'll take the derivative with respect to each component of $\\beta$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\beta_j} \\sum_{i} y_i log(p_i) + (1 - y_i) log(1 - p_i) = 0$$\n",
    "\n",
    "After some algebraic manipulation, we find that:\n",
    "\n",
    "$$\\sum_{i} (y_i - p_i) x_{ij} = 0$$\n",
    "\n",
    "If we expand $p_i$, we can see that it is not possible so solve for $\\beta_j$ in a closed form, so we will use an iterative optimization algorithm that approximates the solution by continually moving each $\\beta_j$ in the direction of the steepest gradient at each step.\n",
    "\n",
    "\n",
    "#### Learning algorithm\n",
    "\n",
    "We can iteratively solve for (approximately) optimal parameters by nudging each $\\beta_j$ in the right direction:\n",
    "\n",
    "$$\\beta_j += \\alpha \\sum_{i} (y_i - p_i) x_{ij}$$\n",
    "\n",
    "We define a learning rate, $\\alpha$, to make sure that we are taking small enough steps (so we don't miss the minimum/maximum). Since we do not know the full form of the function, this ensures that we stay on the right path toward the optimum. If you notice the algorithm switching back and forth between parameter values, it usually means your step size is too large. \n",
    "\n",
    "The function defined below puts all of this together.\n",
    "\n",
    "If you are curious about the full derivation of the maximum likelihood approach, check out this [reference](http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(data, data_class, use_ml=True, learn_iters=4000, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Method for learning logistic regression (LR) parameters\n",
    "\n",
    "    :param data: Feature vectors over which we'd like to learn, each row is a record, each column is a feature\n",
    "    :param data_class: Label for the associated record in data\n",
    "    :param learn_iters: Number of iterations to run through our optimization algorithm\n",
    "    :param alpha: Gradient step size (i.e. learning rate)\n",
    "    :return: Vector of learned weighting parameters for LR classifier\n",
    "    \"\"\"\n",
    "    # add bias to input feature vectors\n",
    "    data = add_bias(data)\n",
    "    num_rows, num_features = data.shape\n",
    "    data_class = np.reshape(data_class, (len(data_class),))\n",
    "\n",
    "    # initialize beta vector (LR Weights) to all zeros\n",
    "    betas = np.zeros(num_features)  # np.random.random(num_features)\n",
    "\n",
    "    #\n",
    "    # Iterate through the optimization\n",
    "    #\n",
    "    for iter in range(learn_iters):\n",
    "        # Given our current beta vector, attempt to classify the data\n",
    "        # this is our current guess, we'll then compare that to the true labels\n",
    "        # and attempt to update the beta vector so that we'll be better on the next iteration\n",
    "        guess = logistic(betas, data)\n",
    "\n",
    "        for i in range(len(betas)):\n",
    "            # compute the likelihood of the model\n",
    "            # we don't actually use this, just print it out for logging\n",
    "            llike = np.sum(data_class * np.log(guess + EPS) + (1 - data_class) * np.log(1 - guess + EPS))\n",
    "\n",
    "            if use_ml:\n",
    "                # if we're using the loglikelihood as our objective function,\n",
    "                # this is the derivative for beta_i\n",
    "                diff = np.sum((data_class - guess) * data[:, i])\n",
    "                betas[i] += alpha * diff\n",
    "            else:\n",
    "                # if we're using the squared error as our objective function,\n",
    "                # this is the derivative of beta_i\n",
    "                betas[i] += alpha * 2 * np.sum((data_class - guess) * guess * (1 - guess) * data[:, i])\n",
    "                # note: the constant multiplication by 2 here does not matter. It is technically part of\n",
    "                # the derivative, but because its constant across any data and parameters, we could leave it\n",
    "                # out without any affect on the efficacy of the learner.\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            print(iter, betas, llike)\n",
    "\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's do some learning!!\n",
    "#\n",
    "\n",
    "# It's finally time to put all of this together and turn it into something useful.\n",
    "# we'll give our learning algorithm our feature vectors and their corresponding labels\n",
    "# and get back the learned model parameters.\n",
    "s = time.time()\n",
    "betas_learned = learn(data, data_class, alpha=0.05)\n",
    "e = time.time()\n",
    "\n",
    "# TODO: play around with the parameters for alpha to see how changing the learning rate influences the convergence\n",
    "# what if we had higher dimensional data?\n",
    "\n",
    "\n",
    "print('\\nDone learning... {}s'.format(e - s))\n",
    "print(betas_learned) \n",
    "print('\\n==============\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# reshape data\n",
    "#\n",
    "data1 = add_bias(data)\n",
    "\n",
    "num_rows, num_features = data.shape\n",
    "data_class1 = np.reshape(data_class, (N * 2,))\n",
    "\n",
    "print('Accuracy on training data: {}'.format(accuracy(data1, data_class1, betas_learned)))\n",
    "test_result(betas_learned, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use built-in methods to simplify this code!\n",
    "We build a logistic regression classifier! But what if we don't want to compute our own derivatives? In this case we can simply define our objective function (actually, in this case a loss function which we'll aim to minimize) and use a [standard package](http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.optimize.minimize.html) to do the optimization. \n",
    "\n",
    "Of course there are easier ways to accomplish this, the simplest being [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), but the goal for this tutorial is to understand how things work!\n",
    "\n",
    "To implement our objective function we'll take the log likelihood we defined above and negate it since we're minimizing instead of maximizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# First thing we need to do is write a function that can evaluate our objective function.\n",
    "# The \"llike\" logic should look familiar, this is the maximum likelihood \n",
    "# for binary classification that we defined above. \n",
    "#\n",
    "# We negate the log-likelihood since the scipy function that we're going to use only knows how\n",
    "# to minimize functions. Since this is a likelihood, we'd actually like to maximize it, but by \n",
    "# flipping the sign, we turn this into a loss function!\n",
    "#\n",
    "def objective(betas, data, data_class):\n",
    "    # avoid log(0) = -Inf\n",
    "    predict = logistic(betas, data)\n",
    "\n",
    "    # log likelihood function\n",
    "    llike = -np.sum(data_class * np.log(predict + EPS) + (1 - data_class) * np.log(1 - predict + EPS))\n",
    "    return llike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Plug our objective function into the standard optimizer and let it do it's thing\n",
    "#\n",
    "\n",
    "num_rows, num_features = data1.shape\n",
    "betas = np.zeros(num_features)  # initialize to a vector of 0's to make sure we have a consistent starting point\n",
    "\n",
    "s = time.time()\n",
    "OptimizeResult = minimize(objective, betas, args=(data1, data_class1))\n",
    "beta_learned_scipy = OptimizeResult.x\n",
    "e = time.time()\n",
    "print('\\nDone learning... {}s'.format(e - s))\n",
    "\n",
    "print('BETAS...')\n",
    "print(beta_learned_scipy)\n",
    "\n",
    "print('accuracy on training data: {}'.format(accuracy(data1, data_class1, beta_learned_scipy)))\n",
    "\n",
    "\n",
    "print('test learned classifier')\n",
    "test_result(beta_learned_scipy, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare the parameters we learned from our own implementation vs the scipy minimizer\n",
    "# these values should be nearly identical since we're optimizing the same function in both cases\n",
    "print('learned from our custom code')\n",
    "print(betas_learned)\n",
    "print('\\nlearned from the scipy optimize method')\n",
    "print(beta_learned_scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "\n",
    "Both methods seem to provide the same results. This is good, this means we were doing the right thing!\n",
    "You may also have noticed that our custom code took ~20X longer to execute than the scipy method. \n",
    "This is expected since scipy is all highly optimized C code under the covers. They are also probably implementing smarter stopping criteria than we had.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "So far we've manually implemented gradient descent, and we've used scipy's built-in `minimize()` method. Next, we're going to setup and implement the problem in tensorflow!\n",
    "\n",
    "Although Tensorflow is often associated with deep learning, it is in fact a generic library that can help you setup and execute complicated mathematical functions and optimization routines. Unlike numpy that executes as normal python code, tensorflow has lazy execution. You first setup your \"computational graph\", then tensorflow will figure out how to execute over that graph depending on what outputs you are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph - this allows us to redefine variables and the graph structure \n",
    "# (i.e. you can run this cell multiple times without getting an error)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_rows = data_class1.size\n",
    "# print('num rows = ', num_rows)\n",
    "num_dims = data1[0].size\n",
    "\n",
    "\n",
    "# ----\n",
    "# create graph\n",
    "# ----\n",
    "\n",
    "# weight vector, this is what we're going to learn from our data.\n",
    "# In tensorflow, things that are learnable are \"variables\" - as you'll see below, tensorflow will automatically\n",
    "# update these values as I setup my optimization problem.\n",
    "betas = tf.get_variable(\"betas\", shape=[1, num_dims], initializer=tf.zeros_initializer())\n",
    "\n",
    "# The next 2 items are placeholders, these are things that will be defined by input data.\n",
    "# X is our set of features and y_true is the vector of true labels.\n",
    "# Placeholders differ from variables as they are just what they sound like - they hold a place in the computational\n",
    "# graph and wait to get filled in by user defined inputs.\n",
    "X = tf.placeholder(tf.float32, shape=[num_dims, None], name=\"data\")\n",
    "y_true = tf.placeholder(tf.float32, shape=[1, None], name=\"y\")\n",
    "\n",
    "# This is the core of logistic regression: multiplying betas by our input and pushing that into a logistic function\n",
    "with tf.name_scope('y_pred') as scope:\n",
    "    y_pred = tf.sigmoid(tf.matmul(betas, X, name=\"mult\"), name=\"logistic\")\n",
    "\n",
    "\n",
    "# Lastly, we define how to compute our loss function.\n",
    "# This is the same as what we did above in our `objective()` method - negate the log-likelihood. \n",
    "with tf.name_scope('loss') as scope:\n",
    "    loss = -tf.reduce_sum(tf.multiply(y_true, tf.log(y_pred + EPS), name=\"positive_loss\") + \n",
    "                          tf.multiply((1 - y_true), tf.log(1 - y_pred + EPS), name=\"negative_loss\"), axis=1)\n",
    "\n",
    "# Now we'll tell tensorflow what we want it to do: use gradient descent with the following learning rate to\n",
    "# minimize our loss function. Because of the computational graph we've defined, Tensorflow knows that \n",
    "# it can only change Variables (i.e. it can only minimize this function by updating the betas vector)\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "\n",
    "# -- debug\n",
    "# loss_parts = tf.multiply(y_true, tf.log(y_pred + EPS)) + tf.multiply((1 - y_true), tf.log(1 - y_pred + EPS))\n",
    "# print_m = tf.Print(m, [X, betas])\n",
    "# print_betas = tf.Print(betas, [betas])\n",
    "# p_loss = tf.Print(loss_parts, [y_pred, y_true])\n",
    "# p_ypred = tf.Print(y_pred, [m])\n",
    "# p_ytrue = tf.Print(y_true, [y_true])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 4000\n",
    "show_debug_info = False\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    # this will initialize all of our variables. You can see in our definition above, after this call\n",
    "    # our betas vector will be set to a vector of 0's\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    if show_debug_info:\n",
    "        x_, ytrue_, mm_, yp_, loss_, loss1_ = sess.run([X, y_true, m, y_pred, loss_parts, loss],\n",
    "                                                       feed_dict={X: np.transpose(data1[98:102]), \n",
    "                                                                  y_true: np.reshape(data_class1[98:102], (1,4))})\n",
    "\n",
    "        print('x')\n",
    "        print(x_)\n",
    "        print('y true')\n",
    "        print(ytrue_)\n",
    "        print('m')\n",
    "        print(mm_)\n",
    "        print('ypred')\n",
    "        print(yp_)\n",
    "        print('loss vector')\n",
    "        print(loss_)\n",
    "        print('loss (summed)')\n",
    "        print(loss1_)\n",
    "    \n",
    "    for i in range(NUM_EPOCHS):\n",
    "        \n",
    "        # `feed_dict` is how we feed data into our placeholders defined above.\n",
    "        # this is our training routine, so we're passing in the data and the true labels so that\n",
    "        # we can optimize our weights\n",
    "\n",
    "        _, loss_, betas_ = sess.run([optimizer, loss, betas], \n",
    "                                     feed_dict={X: np.transpose(data1), \n",
    "                                                y_true: np.reshape(data_class, (1, num_rows))})\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print('----\\n')\n",
    "            print('[{}] total_loss: {}'.format(i, loss_))\n",
    "            print('betas:')\n",
    "            print(betas_)\n",
    "\n",
    "    tf_learned_betas = sess.run([betas])\n",
    "writer.close()\n",
    "\n",
    "\n",
    "# To see the structure of this graph using tensorboard:\n",
    "# tensorboard --logdir=graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('learned from tensorflow')\n",
    "print(tf_learned_betas[0])\n",
    "print('\\nlearned from our custom code')\n",
    "print(betas_learned)\n",
    "print('\\nlearned from the scipy optimize method')\n",
    "print(beta_learned_scipy)\n",
    "\n",
    "print('\\naccuracy on training data: {}'.format(accuracy(data1, data_class1, tf_learned_betas)))\n",
    "\n",
    "print('------------\\ntest learned classifier')\n",
    "test_result(tf_learned_betas, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tada!\n",
    "\n",
    "We learn the (almost) same set of weights across all three methods! Success!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
